<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts">
  <meta name="keywords" content="Value-Spectrum, VLM Agents, Benchmark, VLMs, Social Media">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts</title>

  <link rel="icon" href="./assets/logos/valuespectrum.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/tool_cards.css">
  <link rel="stylesheet" href="./static/css/top_button.css">
  <link rel="stylesheet" href="./static/css/navbar.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/video.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>

  <!-- Add navbar.js script -->
  <script src="./static/js/navbar.js"></script>

  <!-- Add MathJax -->
  <script src="./static/js/mathjax.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- Add visualization.js script -->
  <script src="./static/js/visualization.js"></script>

</head>


<body>

  <!-- Add Table of Contents -->
  <div class="toc-wrapper">
    <h4 style="margin-bottom: 10px;">
      <a href="#">Table of Contents</a>
    </h4>
    <ul class="toc-list">
      <li><a href="#introduction">Introduction</a></li>
      <li><a href="#video">YouTube Video</a></li>
      <li><a href="#dataset">Dataset</a></li>
      <li>
        <a href="#results">Results</a>
        <!-- <div class="toc-subitem">
          <a href="#main-results">Main Results</a>
          <a href="#ablation-study">Ablation Study</a>
        </div> -->
      </li>
      <li><a href="#BibTeX">BibTeX</a></li>
    </ul>
  </div>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <img src="assets/logos/valuespectrum.png" style="width:1em;vertical-align: middle" alt="Logo">
            <span style="vertical-align: middle">
              <span style="vertical-align: middle;">
                <span style="color: grey;">Value</span>
                <span style="color: black;">-</span>
                <span style="color: var(--color-s);">S</span><span style="color: var(--color-p);">p</span><span style="color: var(--color-e);">e</span><span style="color: var(--color-c);">c</span><span style="color: var(--color-t);">t</span><span style="color: var(--color-r);">r</span><span style="color: var(--color-u);">u</span><span style="color: var(--color-m);">m</span>
              </span>
            </span>
          </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            Quantifying Preferences of Vision-Language Models via <br> Value Decomposition in Social Media Contexts
          </h2>

          <!-- Authors on one line -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">Jingxuan Li*<sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://jeremyyny.github.io/" target="_blank">Yuning Yang</a>*<sup>1</sup>
              <a href="mailto:yuningyangai@gmail.com"><i class="fas fa-envelope"></i></a>,
            </span>
            <span class="author-block">Shengqi Yang<sup>2</sup>,</span>
            <span class="author-block">Linfan Zhang<sup>1</sup>,</span>
            <span class="author-block"><a href="http://www.stat.ucla.edu/~ywu/" target="_blank">Ying Nian Wu</a><sup>1</sup></span>
          </div>

          <!-- Affiliations on one line, below authors -->
          <div class="is-size-5 publication-authors" style="margin-top: 0.25em;">
            <span class="author-block"><sup>1</sup>University of California, Los Angeles; <sup>2</sup>Los Alamos National Laboratory</span>
          </div>

          <!-- Equal contribution on its own line, below affiliations -->
          <div class="is-size-5 publication-authors" style="margin-top: 0.25em;">
            <span class="paper-block"><b>*Equal contribution, alphabetical by first name</b></span>
          </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/pdf/2502.11271.pdf"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span> -->
                <!-- arxiv link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2411.11479" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/Jeremyyny/Value-Spectrum"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- PyPI Link. -->
                <!-- <span class="link-block">
                  <a href="https://pypi.org/project/octotoolkit/"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üì¶</p>
                    </span>
                    <span>PyPI</span>
                  </a>
                </span>     -->
                <!-- Demo Link. -->
                <!-- <span class="link-block">
                  <a href="https://huggingface.co/spaces/OctoTools/octotools"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">ü§ó</p>
                    </span>
                    <span>Demo</span>
                  </a>
                </span> -->
                <!-- Visualization Link. -->
                <!-- <span class="link-block">
                  <a href="#visualization"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üîÆ</p>
                    </span>
                    <span>Visualize</span>
                  </a>
                </span> -->
                <!-- YouTube Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=IHaVexkSuEE"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üì∫</p>
                    </span>
                    <span>YouTube</span>
                  </a>
                </span>            
                <!-- Twitter Link. -->
                <!-- <span class="link-block">
                  <a href="https://x.com/lupantech/status/1892260474320015861"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üåê</p>
                    </span>
                    <span>Twitter</span>
                  </a>
                </span> -->
                <!-- Discord Link. -->
                <!-- <span class="link-block">
                  <a href="https://discord.gg/kgUXdZHgNG"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üí¨</p>
                    </span>
                    <span>Discord</span>
                  </a>
                </span> -->
                <!-- Slack Link. -->
                <!-- <span class="link-block">
                  <a href="https://join.slack.com/t/octotools/shared_invite/zt-3485ikfas-zMTbFbuodJmET~R6KXHEGw"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üí¨</p>
                    </span>
                    <span>Slack</span>
                  </a>
                </span> -->
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

<section class="section" id="introduction">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- 1. Update the title -->
        <h2 class="title is-3">Introduction</h2>
      <div class="content has-text-centered"> <!-- This div centers its block children if they aren't full width -->
        <img src="assets/models/value_pipeline.png" width="100%" alt="Value-Spectrum Framework Overview">
        <p style="text-align: left;"> <!-- Introductory text remains left-aligned -->
          We introduce <b>Value-Spectrum</b>, a benchmark designed to systematically evaluate preference traits in Vision-Language Models (VLMs) through visual content from social media, based on Schwartz‚Äôs core human values:
        </p>
        <!-- Move the UL outside the left-aligned P, but still inside the centered DIV -->
        <ul class="value-list" style="list-style-type: none; padding-left: 0; margin-top: 0.5em; display: inline-block; text-align: left;">
            <li>ü§ù <b>Benevolence</b> ‚Äî caring for and helping others</li>
            <li>üåç <b>Universalism</b> ‚Äî understanding, appreciation, and protection of all people and nature</li>
            <li>üß≠ <b>Self-Direction</b> ‚Äî independent thought and action</li>
            <li>üèÜ <b>Achievement</b> ‚Äî personal success through demonstrating competence</li>
            <li>üé¢ <b>Stimulation</b> ‚Äî excitement, novelty, and challenge in life</li>
            <li>üç∞ <b>Hedonism</b> ‚Äî pleasure and sensuous gratification</li>
            <li>üõ°Ô∏è <b>Security</b> ‚Äî safety, harmony, and stability of society and relationships</li>
            <li>üìè <b>Conformity</b> ‚Äî restraint of actions that might upset others or violate social norms</li>
            <li>üßß <b>Tradition</b> ‚Äî respect, commitment, and acceptance of cultural or religious customs</li>
            <li>üëë <b>Power</b> ‚Äî social status, prestige, and control over people and resources</li>
        </ul>
      </div>
      <div class="content has-text-centered" style="margin-top: 2rem;"> <!-- Added some margin-top for better spacing -->
        <!-- Make sure 'assets/models/agent_pipeline.png' visually represents the data collection or agent interaction -->
        <img src="assets/models/agent_pipeline.png" width="100%" alt="Value-Spectrum Data Collection Pipeline">
        <p style="text-align: left;">
          <b>Value-Spectrum</b> utilizes VLM agents embedded within social media platforms (e.g., TikTok, YouTube, etc.) to collect a dataset of 50,191 unique short video screenshots. These screenshots span a wide range of topics, including lifestyle, technology, health, and more.
        </p>
      </div>
    </div>
  </section>


<!-- YouTube Video -->
<section class="section video-section" id="video">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 video-title">YouTube Video</h2>
        <div class="publication-video video-container">
          <iframe src="https://www.youtube.com/embed/IHaVexkSuEE"  <!-- Corrected src -->
                  frameborder="0"
                  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen>
          </iframe>
        </div>
        <p class="has-text-centered mt-4">
          Powered by <a href="https://notebooklm.google/" target="_blank">NotebookLLM</a> for generating this podcast! <!-- Corrected link -->
        </p>
      </div>
    </div>
  </div>
</section>
<!--/ YouTube Video -->

<!-- Data Set -->
<section class="section" id="dataset">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- 1. Update the title -->
        <h2 class="title is-3">Value-Spectrum Dataset</h2>

        <!-- 2. Add a placeholder for your dataset image -->
        <!-- You'll need to replace 'path/to/your/dataset_image.jpg' with the actual path to your image -->
        <!-- It's often good to have an image that represents your data or collection process -->
        <figure class="image is-16by9" style="margin-bottom: 1.5rem;">
          <img src="assets/models/dataset.png" alt="Dataset Overview Image">
          <!-- Example: <img src="images/dataset_pipeline_or_distribution.png" alt="Social Media Video Dataset Overview"> -->
        </figure>

        <div class="content has-text-justified">
          <!-- 3. Add the new, concise dataset description -->
          <p>
  We introduce a novel dataset comprising <strong>50,191 single-frame images</strong>, each extracted from a short video sourced from Instagram, YouTube, and TikTok. These source videos span multiple months and cover diverse topics, including family, health, hobbies, society, technology, etc.
  A key feature of this dataset is its annotation: each image is mapped to one or more of the <strong>10 core human values from Schwartz's theory</strong> via keyword matching.
  In addition to the annotated image, each entry includes the <strong>original video link, relevant platform metadata</strong> (such as platform name and post date), <strong>and the VLMs‚Äò preference answers (e.g., like or dislike) for the image.</strong>
  This rich collection, captured between July and October 2024 through an VLM-driven GUI agent, is structured in a vector database to facilitate research into VLM behavior, content preferences, and value decomposition across diverse social media landscapes.
  Our dataset aims to empower deeper insights into model interpretation and the dynamics of online content.   The full dataset, with its value annotations, is currently being prepared for public release on <a href="https://huggingface.co/datasets" target="_blank">Hugging Face</a> and will be available soon.
</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!--/ Data Set -->


  <!-- Results -->
<section class="section" id="results">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experimental Results</h2>
        <h3 class="title is-4">Main Results: Comparison with Baselines</h3>
        <div class="content has-text-justified">
          <p>
            To demonstrate the generality of our <span style="color: var(--color-octo-red);"><b>Octo</b></span><span
              style="color: var(--color-tools-blue);"><b>Tools</b></span> framework, we conduct comprehensive
            evaluations on <b>16 diverse benchmarks</b> spanning <b>two modalities</b>, <b>five domains</b>, and
            <b>four reasoning types</b>. These benchmarks encompass a wide range of complex reasoning tasks, including
            <b>visual understanding</b>, <b>numerical calculation</b>, <b>knowledge retrieval</b>, and <b>multi-step
              reasoning</b>.
          </p>

          <!-- Changed ID to be unique -->
          <div id="main-results-carousel" class="carousel results-carousel">
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="assets/results/table_result.png" width="90%" alt="Main results table">
                <!-- <p> Caption. </p> -->
              </div>
            </div>

            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="assets/results/vlm_prefer_score.png" width="90%" alt="VLM preference score comparison">
                <!-- Stylistic change to the caption's first sentence -->
                <p>
                  Performance comparison of our framework against other agents. Our framework consistently outperforms
                  agent baselines across all benchmarks. Bar values represent accuracy and error bars represent
                  standard deviation.
                </p>
              </div>
            </div>

            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="assets/results/vlm_spider.png" width="45%" alt="VLM performance gains spider chart">
                <p> Performance gains across different benchmarks from our <span
                    style="color: var(--color-octo-red);"><b>Octo</b></span><span
                    style="color: var(--color-tools-blue);"><b>Tools</b></span> framework over the base GPT-4o model.
                </p>
              </div>
            </div>

            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="assets/results/vlm_std.png" width="50%" alt="VLM standard deviation comparison">
                <p> Comparison with other agent frameworks using the same underlying toolbox. <span
                    style="color: var(--color-octo-red);"><b>Octo</b></span><span
                    style="color: var(--color-tools-blue);"><b>Tools</b></span> achieves superior performance with an
                  average accuracy of 58.5%, outperforming the next best baseline by 7.3%. Results are averaged over
                  three trials.
                </p>
              </div>
            </div>


            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="assets/results/agent_persona.png" width="50%" alt="Agent persona exploration results">
                <p> Exploring Value-Driven Role-Playing in Vision-Language Models. This study investigates how VLMs
                  adopt assigned personas to align value traits and preferences within social media contexts.
                </p>
              </div>
            </div>

            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="assets/results/agent_score_platform.png" width="50%" alt="Agent score by platform">
                <p> Each VLM‚Äôs percentage score of preference alignment changes across TikTok, YouTube, and
                  Instagram. Positive values indicate an increase in alignment, while negative values represent a
                  decrease.
                </p>
              </div>
            </div>

          </div>
        </div>
        <h3 class="title is-4">Ablation Study: VLMs vs. Corresponding LLMs</h3>
        <div class="content has-text-justified">
          <p>
            We further explore several factors that affect <span
              style="color: var(--color-octo-red);"><b>Octo</b></span><span
              style="color: var(--color-tools-blue);"><b>Tools</b></span>'s performance, using a validation set of 100
            samples.
          </p>

          <!-- Changed ID to be unique -->
          <div id="ablation-results-carousel" class="carousel results-carousel">
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="assets/ablation/ablation_1.png" width="90%" alt="Ablation study results 1">
                <p> Value Distribution Comparison between VLMs and corresponding LLMs. For the same model
                  (e.g., GPT-4o and GPT-4o_text), different input modes (multi-modal vs. text-only) are compared.
                  Experiments demonstrate that the choice of multi-modal input significantly influences some models‚Äô
                  value preferences. While models like GPT-4o show consistency across input modes, others, such as
                  Claude 3.5 Sonnet and Gemini 1.5 Pro, exhibit notable differences in preferences.
                </p>
              </div>
            </div>

            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="assets/ablation/ablation_2.png" width="90%" alt="Ablation study results 2">
                <p> Value preference outcomes across different models and input settings on Value-Spectrum. The
                  settings include direct multi-modal responses from Vision-Language Models (VLMs) and combinations of
                  image descriptions generated by different VLMs with Large Language Models (LLMs).
                </p>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
  <!--/ Results -->

  

  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title is-3 has-text-centered">BibTeX</h2>
      <pre><code>@inproceedings{Li2024ValueSpectrumQP,
  title={Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts},
  author={Jingxuan Li and Yuning Yang and Shengqi Yang and Linfan Zhang and Ying Nian Wu},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2025},
}</code></pre>
    </div>
  </section>

  <section>
    <div class="section" id="org-banners" style="display:flex">
      <a href="https://www.ucla.edu/" target="_blank" rel="external">
        <img class="center-block org-banner" src="assets/logos/logo_UCLA_blue_boxed.png">
      </a>
      <!-- <a href="https://ai.stanford.edu/" target="_blank" rel="external">
        <img class="center-block org-banner" src="assets/logos/ai_stanford.png"> -->
      </a>
    </div>
  </section>


  <!-- License -->
  <footer class="footer">
    <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a> and <a
              href="https://OctoTools.github.io/">OctoTools</a>, licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
    <!-- </div> -->
  </footer>

</body>

  <!-- Back to top button -->
  <button onclick="topFunction()" id="topButton" title="Go to top">
    <i class="fas fa-arrow-up"></i>
  </button>


  
</html>
