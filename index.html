<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts">
  <meta name="keywords" content="Value-Spectrum, VLM Agents, Benchmark, VLMs, Social Media">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts</title>

  <link rel="icon" href="./assets/logos/valuespectrum.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/tool_cards.css">
  <link rel="stylesheet" href="./static/css/top_button.css">
  <link rel="stylesheet" href="./static/css/navbar.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/video.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>

  <!-- Add navbar.js script -->
  <script src="./static/js/navbar.js"></script>

  <!-- Add MathJax -->
  <script src="./static/js/mathjax.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- Add visualization.js script -->
  <script src="./static/js/visualization.js"></script>

</head>


<body>

  <!-- Add Table of Contents -->
  <div class="toc-wrapper">
    <h4 style="margin-bottom: 10px;">
      <a href="#">Table of Contents</a>
    </h4>
    <ul class="toc-list">
      <li><a href="#introduction">Introduction</a></li>
      <li><a href="#video">YouTube Video</a></li>
      <li><a href="#dataset">Dataset</a></li>
      <li><a href="#visualization">Visualization</a></li>
      <li>
        <a href="#framework">Framework</a>
        <!-- <div class="toc-subitem">
          <a href="#task-specific-tool-selection">Task-Specific Tool Selection</a>
        </div> -->
      </li>
      <li>
        <a href="#results">Results</a>
        <!-- <div class="toc-subitem">
          <a href="#main-results">Main Results</a>
          <a href="#ablation-study">Ablation Study</a>
        </div> -->
      </li>
      <li><a href="#Share">Share</a></li>
      <li><a href="#BibTeX">BibTeX</a></li>
    </ul>
  </div>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title is-bold">
              <img src="assets/logos/valuespectrum.png" style="width:1em;vertical-align: middle" alt="Logo">
              <span style="vertical-align: middle">
                             <span style="vertical-align: middle;">
                <span style="color: grey;">Value</span><!-- "Value" in black -->
                <span style="color: black;">-</span>
                <span style="color: var(--color-s);">S</span
                ><span style="color: var(--color-p);">p</span
                ><span style="color: var(--color-e);">e</span
                ><span style="color: var(--color-c);">c</span
                ><span style="color: var(--color-t);">t</span
                ><span style="color: var(--color-r);">r</span
                ><span style="color: var(--color-u);">u</span
                ><span style="color: var(--color-m);">m</span>
              </span>
            </h1>
              </span>
            </h1>
            <h2 class="subtitle is-3 publication-subtitle">
              Quantifying Preferences of Vision-Language Models via <br> Value Decomposition in Social Media Contexts
            </h2>
                        <div class="is-size-5 publication-authors">
            <span class="author-block">
                  Jingxuan Li*<sup>1</sup>
                </span>
                <span class="author-block">
                  <a href="https://jeremyyny.github.io/" target="_blank">Yuning Yang</a>*<sup>1</sup>
                  <a href="mailto:yuningyangai@gmail.com"><i class="fas fa-envelope"></i></a>,
                </span>
                <span class="author-block">
                  Shengqi Yang<sup>2</sup>,
                </span>
                <span class="author-block">
                  Linfan Zhang<sup>1</sup>,
                </span>
                <span class="author-block">
                  <a href="http://www.stat.ucla.edu/~ywu/" target="_blank">Ying Nian Wu</a><sup>1</sup>
                </span>
              </div>

              <div class="is-size-5 publication-authors" style="margin-top: 0.5em;"> <!-- Affiliations block -->
                <span class="author-block"><sup>1</sup>University of California, Los Angeles </span> <span class="author-block"><sup>2</sup>Los Alamos National Laboratory</span><br>
                <span class="paper-block"><b>*Equal contribution, alphabetical by first name</b></span>
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/pdf/2502.11271.pdf"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span> -->
                <!-- arxiv link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2411.11479" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/Jeremyyny/Value-Spectrum"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- PyPI Link. -->
                <!-- <span class="link-block">
                  <a href="https://pypi.org/project/octotoolkit/"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üì¶</p>
                    </span>
                    <span>PyPI</span>
                  </a>
                </span>     -->
                <!-- Demo Link. -->
                <!-- <span class="link-block">
                  <a href="https://huggingface.co/spaces/OctoTools/octotools"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">ü§ó</p>
                    </span>
                    <span>Demo</span>
                  </a>
                </span> -->
                <!-- Visualization Link. -->
                <!-- <span class="link-block">
                  <a href="#visualization"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üîÆ</p>
                    </span>
                    <span>Visualize</span>
                  </a>
                </span> -->
                <!-- YouTube Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=IHaVexkSuEE"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üì∫</p>
                    </span>
                    <span>YouTube</span>
                  </a>
                </span>            
                <!-- Twitter Link. -->
                <!-- <span class="link-block">
                  <a href="https://x.com/lupantech/status/1892260474320015861"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üåê</p>
                    </span>
                    <span>Twitter</span>
                  </a>
                </span> -->
                <!-- Discord Link. -->
                <!-- <span class="link-block">
                  <a href="https://discord.gg/kgUXdZHgNG"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üí¨</p>
                    </span>
                    <span>Discord</span>
                  </a>
                </span> -->
                <!-- Slack Link. -->
                <!-- <span class="link-block">
                  <a href="https://join.slack.com/t/octotools/shared_invite/zt-3485ikfas-zMTbFbuodJmET~R6KXHEGw"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <p style="font-size:18px">üí¨</p>
                    </span>
                    <span>Slack</span>
                  </a>
                </span> -->
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

<section class="section" id="introduction">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- 1. Update the title -->
        <h2 class="title is-3">Introduction</h2>
      <div class="content has-text-centered"> <!-- This div centers its block children if they aren't full width -->
        <img src="assets/models/value_pipeline.png" width="100%" alt="Value-Spectrum Framework Overview">
        <p style="text-align: left;"> <!-- Introductory text remains left-aligned -->
          We introduce <b>Value-Spectrum</b>, a benchmark designed to systematically evaluate preference traits in Vision-Language Models (VLMs) through visual content from social media, based on Schwartz‚Äôs core human values:
        </p>
        <!-- Move the UL outside the left-aligned P, but still inside the centered DIV -->
        <ul class="value-list" style="list-style-type: none; padding-left: 0; margin-top: 0.5em; display: inline-block; text-align: left;">
            <li>ü§ù <b>Benevolence</b> ‚Äî caring for and helping others</li>
            <li>üåç <b>Universalism</b> ‚Äî understanding, appreciation, and protection of all people and nature</li>
            <li>üß≠ <b>Self-Direction</b> ‚Äî independent thought and action</li>
            <li>üèÜ <b>Achievement</b> ‚Äî personal success through demonstrating competence</li>
            <li>üé¢ <b>Stimulation</b> ‚Äî excitement, novelty, and challenge in life</li>
            <li>üç∞ <b>Hedonism</b> ‚Äî pleasure and sensuous gratification</li>
            <li>üõ°Ô∏è <b>Security</b> ‚Äî safety, harmony, and stability of society and relationships</li>
            <li>üìè <b>Conformity</b> ‚Äî restraint of actions that might upset others or violate social norms</li>
            <li>üßß <b>Tradition</b> ‚Äî respect, commitment, and acceptance of cultural or religious customs</li>
            <li>üëë <b>Power</b> ‚Äî social status, prestige, and control over people and resources</li>
        </ul>
      </div>
      <div class="content has-text-centered" style="margin-top: 2rem;"> <!-- Added some margin-top for better spacing -->
        <!-- Make sure 'assets/models/agent_pipeline.png' visually represents the data collection or agent interaction -->
        <img src="assets/models/agent_pipeline.png" width="100%" alt="Value-Spectrum Data Collection Pipeline">
        <p style="text-align: left;">
          <b>Value-Spectrum</b> utilizes VLM agents embedded within social media platforms (e.g., TikTok, YouTube, etc.) to collect a dataset of 50,191 unique short video screenshots. These screenshots span a wide range of topics, including lifestyle, technology, health, and more.
        </p>
      </div>
    </div>
  </section>


<!-- YouTube Video -->
<section class="section video-section" id="video">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 video-title">YouTube Video</h2>
        <div class="publication-video video-container">
          <iframe src="https://www.youtube.com/embed/IHaVexkSuEE"  <!-- Corrected src -->
                  frameborder="0"
                  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen>
          </iframe>
        </div>
        <p class="has-text-centered mt-4">
          Powered by <a href="https://notebooklm.google/" target="_blank">NotebookLLM</a> for generating this podcast! <!-- Corrected link -->
        </p>
      </div>
    </div>
  </div>
</section>
<!--/ YouTube Video -->

<!-- Data Set -->
<section class="section" id="dataset">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- 1. Update the title -->
        <h2 class="title is-3">Value-Spectrum Dataset</h2>

        <!-- 2. Add a placeholder for your dataset image -->
        <!-- You'll need to replace 'path/to/your/dataset_image.jpg' with the actual path to your image -->
        <!-- It's often good to have an image that represents your data or collection process -->
        <figure class="image is-16by9" style="margin-bottom: 1.5rem;">
          <img src="assets/models/dataset.png" alt="Dataset Overview Image">
          <!-- Example: <img src="images/dataset_pipeline_or_distribution.png" alt="Social Media Video Dataset Overview"> -->
        </figure>

        <div class="content has-text-justified">
          <!-- 3. Add the new, concise dataset description -->
          <p>
  We introduce a novel dataset comprising <strong>50,191 single-frame images</strong>, each extracted from a short video sourced from Instagram, YouTube, and TikTok. These source videos span multiple months and cover diverse topics, including family, health, hobbies, society, technology, etc.
  A key feature of this dataset is its annotation: each image is mapped to one or more of the <strong>10 core human values from Schwartz's theory</strong> via keyword matching.
  In addition to the annotated image, each entry includes the <strong>original video link, relevant platform metadata</strong> (such as platform name and post date), <strong>and the VLM's preference indication (e.g., like or dislike) for the image.</strong>
  This rich collection, captured between July and October 2024 through an VLM-driven GUI agent, is structured in a vector database to facilitate research into VLM behavior, content preferences, and value decomposition across diverse social media landscapes.
  Our dataset aims to empower deeper insights into model interpretation and the dynamics of online content.   The full dataset, with its value annotations, is currently being prepared for public release on <a href="https://huggingface.co/datasets" target="_blank">Hugging Face</a> and will be available soon.
</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!--/ Data Set -->

<!-- Examples -->
<section class="section" id="visualization">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" id="visualization">Visualization Examples</h2>
        
        <!-- Example Selection Buttons -->
        <div class="buttons is-centered" style="margin-bottom: 2rem;">
          <!-- First Row -->
          <div class="buttons has-addons is-centered" style="width: 100%; margin-bottom: 0.5rem;">
            <button class="button is-info is-outlined example-button" data-example="1">
              Demonstration
            </button>
            <button class="button is-info is-outlined example-button" data-example="2">
              Visual Reasoning
            </button>
            <button class="button is-info is-outlined example-button" data-example="3">
              Multi-step Reasoning
            </button>
            <button class="button is-info is-outlined example-button" data-example="4">
              Agentic Reasoning
            </button>
          </div>
          
          <!-- Second Row -->
          <div class="buttons has-addons is-centered" style="width: 100%;">
            <button class="button is-info is-outlined example-button" data-example="5">
              Scientific Reasoning
            </button>
            <button class="button is-info is-outlined example-button" data-example="6">
              Medical Reasoning
            </button>
            <button class="button is-info is-outlined example-button" data-example="7">
              Pathology Diagnosis
            </button>
            <button class="button is-info is-outlined example-button" data-example="8">
              Literature Review
            </button>
          </div>
        </div>

        <!-- Example Display Container -->
        <div id="example-container" style="width: 100%; height: 900px; margin-bottom: 200px; border: none;">
          <!-- The iframe will be inserted here by JavaScript -->
        </div>

      </div>
    </div>
  </div>
</section>

  <!-- Framework -->
  <section class="section" id="framework">
    <div class="container" style="margin-bottom: 2vh;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">The <span style="color: var(--color-octo-red);"><b>Octo</b></span><span
              style="color: var(--color-tools-blue);"><b>Tools</b></span> Framework</h2>
          <div class="content has-text-justified">
            <p>
              We propose <span style="color: var(--color-octo-red);"><b>Octo</b></span><span
                style="color: var(--color-tools-blue);"><b>Tools</b></span>, an open-source, versatile, and
              user-friendly agent-toolbox framework for <b>complex reasoning</b> tasks. Given a user query $q \in
              \mathcal{Q}$ and a pretrained language model $\text{LLM}_\theta(\cdot)$, a naive approach would generate
              an output directly as $y \sim \text{LLM}_\theta(q)$, providing a single-step response. In contrast, our
              <span style="color: var(--color-octo-red);"><b>Octo</b></span><span
                style="color: var(--color-tools-blue);"><b>Tools</b></span> framework introduces a <b>structured</b>,
              <b>multi-step</b> process that leverages <b>external tools</b> to tackle queries effectively.
            </p>
            <p>
              Specifically, <span style="color: var(--color-octo-red);"><b>Octo</b></span><span
                style="color: var(--color-tools-blue);"><b>Tools</b></span> contains a set of <b>tools</b> $\mathcal{D}
              = \{d_i\}_{i=1}^n$ and associated metadata $\mathcal{M} = \{m_i\}_{i=1}^n$, where $n$ is the number of
              available tools. Given a query, a <b>planner</b> (based on a language model) first generates a
              <b>tentative plan</b> from a high-level perspective, indicating how these tools can be used to address the
              query, which forms the initial <b>context</b> $s_0$. From this plan, the planner determines the initial
              <b>action</b> $a_1$ for tool usage, specifying which tool $d_1$ to use, the relevant context, and a
              sub-goal. An <b>executor</b> (also powered by a language model) then converts the planner's text-based
              action $a_1$ into a machine-executable <b>command</b> $o_t$, which is run to obtain intermediate results
              $r_1$. These results, along with the original action, update the context to $s_1 := (a_1, o_1, r_1)$. This
              process constitutes one step in our framework.
            </p>
            <p>
              This process repeats, with the planner iteratively refining its actions based on the evolving context
              until it either finds a complete solution or inference limits (e.g., time or steps) are reached. After $T$
              steps, the framework produces a full <b>trajectory</b> $(s_0, s_1, \dots, s_T)$, which is stored in a
              structured manner in the context. The planner then uses this trajectory to generate the <b>final
                solution</b> to the original query.
            </p>
            <p>
              To sum up, <span style="color: var(--color-octo-red);"><b>Octo</b></span><span
                style="color: var(--color-tools-blue);"><b>Tools</b></span> provides a robust and effective framework
              for solving complex tasks through sub-goal decomposition and systematical tool usage. Standardized <b>tool
                cards</b> encapsulate functionality , the <b>planner</b> orchestrates both high-level and low-level task
              planning, and the <b>executor</b> instantiates tool calls for each sub-goal.
            </p>
          </div>
          <h3 class="title is-4">Task-Specific Tool Selection</h3>
          <div class="content has-text-justified">
            <p>
              The <span style="color: var(--color-octo-red);"><b>Octo</b></span><span
                style="color: var(--color-tools-blue);"><b>Tools</b></span> toolbox contains a diverse set of tools
              covering different modalities and skills. By leveraging structured tool cards and robust planning
              capabilities, <span style="color: var(--color-octo-red);"><b>Octo</b></span><span
                style="color: var(--color-tools-blue);"><b>Tools</b></span> demonstrates strong generality when all
              available tools are enabled across different tasks. However, when a small set of validation examples are
              available for a task, configuring a <b>task-specific subset of tools</b> can further enhance efficiency
              and effectiveness.
            </p>
            <p>
              To this end, we propose an automated algorithm to optimize the toolset configuration for each task. Given
              $n$ available tools in the toolbox, the total number of possible subsets is $O(2^n)$, which is
              prohibitively large. To make this tractable, we employ a greedy search strategy that reduces the
              complexity to $O(n)$. Our approach proceeds in three stages.
            </p>
            <div class="container is-max-desktop">
              <div class="content has-text-centered">
                <img src="assets/models/algorithm.png" width="50%">
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!--/ Framework -->


  <!-- Results -->
  <section class="section" id="results">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Experimental Results</h2>
          <h3 class="title is-4">Main Results: Comparison with Baselines</h3>
          <div class="content has-text-justified">
            <p>
              To demonstrate the generality of our <span style="color: var(--color-octo-red);"><b>Octo</b></span><span
                style="color: var(--color-tools-blue);"><b>Tools</b></span> framework, we conduct comprehensive
              evaluations on <b>16 diverse benchmarks</b> spanning <b>two modalities</b>, <b>five domains</b>, and
              <b>four reasoning types</b>. These benchmarks encompass a wide range of complex reasoning tasks, including
              <b>visual understanding</b>, <b>numerical calculation</b>, <b>knowledge retrieval</b>, and <b>multi-step
                reasoning</b>.
            </p>

            <div id="results-carousel" class="carousel results-carousel">
              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/result_table_1.png" width="90%">
                  <!-- <p> Caption.
                  </p> -->
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/benchmark_gains_radar_barplot.png" width="45%">
                  <p> Performance gains across different benchmarks from our <span
                      style="color: var(--color-octo-red);"><b>Octo</b></span><span
                      style="color: var(--color-tools-blue);"><b>Tools</b></span> framework over the base GPT-4o model.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/result_table_2.png" width="50%">
                  <p> Comparison with other agent frameworks using the same underlying toolbox. <span
                      style="color: var(--color-octo-red);"><b>Octo</b></span><span
                      style="color: var(--color-tools-blue);"><b>Tools</b></span> achieves superior performance with an
                    average accuracy of 58.5%, outperforming the next best baseline by 7.3%. Results are averaged over
                    three trials.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/agent_baselines_bar_plot.png" width="90%">
                  <p> Performance ours vs. other agents. Our framework consistently outperforms agent baselines across
                    all benchmarks. Bar
                    values represent accuracy and error bars represent standard deviation.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/tool_usage_ours_baselines.png" width="90%">
                  <p> <b>a.</b> Tool usage distribution in our <span
                      style="color: var(--color-octo-red);"><b>Octo</b></span><span
                      style="color: var(--color-tools-blue);"><b>Tools</b></span> framework and agent baselines by
                    averaging results from 16 tasks. <b>b.</b> Tool usage distribution across 16 tasks in <span
                      style="color: var(--color-octo-red);"><b>Octo</b></span><span
                      style="color: var(--color-tools-blue);"><b>Tools</b></span>. <span
                      style="color: var(--color-octo-red);"><b>Octo</b></span><span
                      style="color: var(--color-tools-blue);"><b>Tools</b></span> takes advantage of different external
                    tools to address task-specific challenges.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/tool_usage_by_16_tasks_AutoGen.png" width="70%">
                  <p> Distribution of tools usage. Frequency of tools used by the <b>AutoGen</b> agent for each
                    benchmark.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/tool_usage_by_16_tasks_LangChain.png" width="70%">
                  <p> Distribution of tools usage. Frequency of tools used by the <b>GPT-Functions</b> agent for each
                    benchmark.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/tool_usage_by_16_tasks_GPT4o-Plugin.png" width="70%">
                  <p> Distribution of tools usage. Frequency of tools used by the <b>LangChain</b> agent for each
                    benchmark.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/num_steps_hist.png" width="60%">
                  <p> Distribution of number of steps used.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/benchmark_distribution_x_steps_y_tools.png" width="50%">
                  <p> Benchmark distribution across average number of steps and fraction of external tool usage (tools
                    that exclude the base tool <b>Generalist_Solution_Generator</b>) in <span
                      style="color: var(--color-octo-red);"><b>Octo</b></span><span
                      style="color: var(--color-tools-blue);"><b>Tools</b></span>.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/results/scatterplot_decomposition_vs_tools.png" width="50%">
                  <p> Benchmark distribution across two dimensions. Tasks that show high improvement from task
                    decomposition likely require multi-step reasoning, while tasks that show high improvement from
                    specialized tools likely require specialized skills.
                  </p>
                </div>
              </div>

            </div>
          </div>
          <h3 class="title is-4">Ablation Study: Disentangling Different Components</h3>
          <div class="content has-text-justified">
            <p>
              We further explore several factors that affect <span
                style="color: var(--color-octo-red);"><b>Octo</b></span><span
                style="color: var(--color-tools-blue);"><b>Tools</b></span>'s performance, using a validation set of 100
              samples.
            </p>

            <div id="results-carousel" class="carousel results-carousel">
              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/ablation/ours_tool_selection_category_scores_bar_chart.png" width="50%">
                  <p> Performance under three toolset strategies in <span
                      style="color: var(--color-octo-red);"><b>Octo</b></span><span
                      style="color: var(--color-tools-blue);"><b>Tools</b></span> across all 16 tasks and various
                    categories (the number in parentheses indicates the number of tasks in each category).
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/ablation/all_tools_ablation.png" width="90%">
                  <p> Performance with vs. without tool selection. While toolset optimization increases performance over
                    using the full toolset in most tasks, even without it, our framework achieves similar performance by
                    naively enabling all possible tools. Bar values represent accuracy and error bars represent standard
                    deviation.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/ablation/gpt4omini_ours_category_scores_bar_chart.png" width="50%">
                  <p> Performance of <span style="color: var(--color-octo-red);"><b>Octo</b></span><span
                      style="color: var(--color-tools-blue);"><b>Tools</b></span> on 16 tasks and various categories
                    using a weaker LLM, GPT-4o-mini, as the base engine. <span
                      style="color: var(--color-octo-red);"><b>Octo</b></span><span
                      style="color: var(--color-tools-blue);"><b>Tools</b></span><sub>base</sub> is the configuration in
                    which only the base <b>Generalist_Solution_Generator</b> tool is enabled. The number in parentheses
                    indicates the number of tasks in each category.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/ablation/gpt4o-mini_bar_plot.png" width="90%">
                  <p> Performance ours vs. other agents. Our framework consistently outperforms agent baselines across
                    all benchmarks. Bar
                    values represent accuracy and error bars represent standard deviation.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/ablation/average_accuracy_by_max_steps_error_range.png" width="40%">
                  <p> Average accuracy across 16 benchmarks with respect to maximum allowed reasoning steps in <span
                      style="color: var(--color-octo-red);"><b>Octo</b></span><span
                      style="color: var(--color-tools-blue);"><b>Tools</b></span>. Overall, performance tends to improve
                    as the maxmum number of steps increases, highlighting the benefit of longer chains of multi-step
                    reasoning.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/ablation/accuracy_vs_max_steps_indiv_delta.png" width="65%">
                  <p> Accuracy vs number of maximum steps. The change in accuracy from a maximum step of 1 is plotted.
                    Most benchmarks improve in performance with the number of allowed steps.
                  </p>
                </div>
              </div>

              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="assets/ablation/toolset.png" width="60%">
                  <p> Optimized tool sets for each benchmark following our Algorithm. A ‚úìindicates that the tool is used
                    for that benchmark.
                  </p>
                </div>
              </div>

            </div>
          </div>
        </div>
      </div>
  </section>
  <!--/ Results -->

  

  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title is-3 has-text-centered">BibTeX</h2>
      <pre><code>@inproceedings{Li2024ValueSpectrumQP,
  title={Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts},
  author={Jingxuan Li and Yuning Yang and Shengqi Yang and Linfan Zhang and Ying Nian Wu},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2025},
}</code></pre>
    </div>
  </section>

  <section>
    <div class="section" id="org-banners" style="display:flex">
      <a href="https://www.ucla.edu/" target="_blank" rel="external">
        <img class="center-block org-banner" src="assets/logos/logo_UCLA_blue_boxed.png">
      </a>
      <!-- <a href="https://ai.stanford.edu/" target="_blank" rel="external">
        <img class="center-block org-banner" src="assets/logos/ai_stanford.png"> -->
      </a>
    </div>
  </section>


  <!-- License -->
  <footer class="footer">
    <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a> and <a
              href="https://OctoTools.github.io/">OctoTools</a>, licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
    <!-- </div> -->
  </footer>

</body>

  <!-- Back to top button -->
  <button onclick="topFunction()" id="topButton" title="Go to top">
    <i class="fas fa-arrow-up"></i>
  </button>


  
</html>
